# 大数据组件笔记

## kafka

### kafka的特点
Kafka 是一个分布式的流式处理平台，具有以下一些显著的特点：

- 分布式架构： Kafka采用分布式架构，数据被分布存储在多个节点上，从而提供了高可用性和容错性。它允许水平扩展，可以很容易地添加更多的节点来处理更大的负载。

- 高吞吐量： Kafka被设计为能够处理高吞吐量的数据流，适用于大规模的数据传输和处理场景。它能够处理数百、甚至数千的消息每秒。

- 低延迟：毫秒级别的消息延迟

- 持久性： Kafka消息是持久的，一旦被写入，它们将被保存在磁盘上，不会因为消费者的读取而被删除。这使得 Kafka 适用于可靠性要求高的场景，如日志和审计。

- 发布-订阅模型： Kafka采用发布-订阅模型，允许生产者发布消息到一个或多个主题（topics），而消费者可以订阅一个或多个主题来接收消息。这种模型使得消息的生产者和消费者能够松散地耦合。

- 水平扩展： Kafka的水平扩展能力使得系统能够适应不断增长的负载需求。通过添加更多的代理节点，可以提高整个系统的吞吐量和容量。

- 持久性日志： Kafka采用一种持久性日志（log）的方式来存储消息，这种结构使得 Kafka 具有高效的读和写操作。

- 流式处理支持： Kafka并不仅仅是一个消息队列，还提供了流处理的支持。通过 Kafka Streams 或其他流处理框架，可以在流数据上执行复杂的实时处理任务。


### kafka中的基本概念

- producer

- consumer

    - 消费者组（Consumer Group）是订阅消息的基本单位。一个消费者组中可以存在多个消费者，一个消费者只能属于一个消费者组。

    - 消费消息时，一个分区只能分配给一个消费者消费。

- broker

- topic

    - partition：分区是对数据进行水平分割和分布式存储的基本单位。

        - 每个分区都是一个有序且不可变的消息序列。消息在被追加到分区日志、文件的时候都会分配一个特定的偏移量（ offset ）。kafka 通过它来保证消息在分区内的顺序性，不过 offset 并不跨越分区

        - 每个主题（topic）都可以被分为多个分区，而每个分区通常由一个 broker 负责

        - 通常一个broker负责一个分区

    - 副本：通过增加副本数量可以提升容灾能力

        - 同一分区的不同副本中保存的是相同的消息。

        - 副本之间是一主多从关系

            - leader 副本负 责处理读写请求

            - follower 副本只负责与 leader副本的消息同步

### kafka中的副本机制

#### AR，ISR，OSR

- AR: 分区中的所有副本统称为 AR (Assigned Replicas)

- ISR: 所有与leader副本保持一定程度同步的副本(包括leader副本在内)组成 ISR On-Sync Replicas

- OSR: 与leader副本同步滞后过多的副本(不包括 leader 副本)组成 OSR (Out-of-Sync Replicas)

- AR = ISR + OSR

#### ISR和OSR的更新

- OSR和ISR的划分：消息会先发送到leader副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步，同步期间内 follower 副本相对于 leader 副本而言会有一定程度的滞后。如果在容忍范围内，则属于ISR，否则属于OSR。

- leader副本跟踪ISR和OSR中follower副本的滞后状态。

    - 当ISR中follower副本落后太多，则将其移动到OSR中

    - 当OSR中follower副本追上进度，则将其移动到ISR中

#### HW和LEO

- HW：high watermark（高水位），标识了一个特定的消息偏移量，消费者只能拉取到这个offset之前的消息（不包括HW）。

- LEO：log end offset的缩写，它标识当前日志文件中下一条待写入消息的offset

- ISR分区中每一个副本都会维护自身的LEO，最小的LEO就是分区的HW。消费者只能消费HW之前的消息（无论从哪个副本消费消息，消息相同，无遗漏）。

### 生产者

#### 同步复制和异步复制

- 同步复制：同步复制要求所有能工作的 follower 副本都复制完，这条消息才会被确认为已成功提交

- 异步复制：数据只要被 leader 副本写入就被认为已经成功提交，followe副本异步从leader副本中复制数据。

#### producer发送消息的三种模式

- 发后即忘：它只管往Kafka中发送消息而并不关心消息是否正确到达

- 同步：通过Send函数返回值Future对象实现同步，同步发送的方式可靠性高，要么消息被发送成功，要么发生异常。 

- 异步：通过send方法的callback函数进行，回调函数通过是否存在异常判断消息发送成功或者失败

#### 重要的生产者参数

- acks : 这个参数用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。

    - acks = 1，默认值即为 l 。生产者发送消息之后，只要分区的 leader 副本成功写入消息，那么它就会收到来自服务端的成功响应。

    - acks = 0，生产者发送消息之后不需要等待任何服务端的响应

    - acks = -1 或 acks = all。生产者在消息发送之后，需要等待 ISR 中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。(但这并不意味着消息就一定可靠，因为 JSR 中可能只有 leader 副本，这样就退化成了 acks= l 的情况)

- max.request.size：这个参数用来限制生产者客户端能发送的消息的最大值

- retries: 用来配置生产者重试的次数，默认值为 0 

- retry.backoff.ms：用来设定两次重试之间的时间间隔




### 消费者

#### 在kafka中，消费者消费主题，主题中包含多个分区，如何确定消费者消费哪一个分区？

- 手动分配分区，在订阅主题时，指定订阅的分区信息

- 自动分配分区，订阅主题时，不指定分区，由kafka自动分配


#### kafka为什么要保存消费位移

kafka会对每一个消费者的消费位移做持久化保存，为了应对：

- 消费者重启

- 产生新的消费者之后的消费再均衡

- 消费者的消费位移保存在kafka主题_consumer_offsets中，消费者在消费完之后需要提交消费位移

#### 位移提交的方式

- 自动提交：

- 手动提交：

    - 同步提交：提交时线程阻塞，提交之后再返回

    - 异步提交：提交时线程不会阻塞

#### 默认位移提交方式

在kafka中默认的消费位移提交方式是自动提交：定期提交，每隔五秒提交将每一个分区中的最大消息位移进行提交

#### 重复消费和消息丢失

- 重复消费：提交的消费位移落后客户端实际消费的位移，因某种原因客户端重新拉取信息，造成重复消费

- 消息丢失：客户端实际消费的位移落后提交的消费位移，因某种原因客户端重新拉取信息，造成消息丢失


#### 再均衡

- 指分区的所属权从一个消费者转移到另一消费者的行为。

- 消费组内既可以增加消费者，也可以减少消费者


#### 什么时候会发生再均衡

- 有新的消费者加入消费组

- 有消费者宕机下线（长时间没有向GroupCoordinator发送心跳等情况）。

- 消费者主动退出消费组

- 消费组所对应的GroupCoordinator节点发生变化

- 消费组订阅的主题或者主题分区数量发生变化

#### 在均衡的步骤

- 第一阶段(find_coordinator)：消费者确定消费组对应的GroupCordinator所在的Broker，并与该broker建立网络连接

- 第二阶段（join_group）：
    
    - 加入该消费组

    - 选举消费组的leader

    - 选举分区分配策略：每个消费者设置自己的分区分配策略，对消费组而言需要从各个消费者分区分配策略中选举一个适合的策略进行整体的分区分配

- 第三阶段（SYNC_GROUP）：

    - leader根据选举出来的分区分配策略实时具体的分区分配

    - 将分区分配方法通过roupCordinator同步给各消费者

- 第四阶段（HEARTBEAT）：
    
    - 消费者确定拉取信息的起始位置后，开始处于正常的工作状态。

    - 消费者向groupCordinator发送心跳来维护她们与消费组的从属关系，以及对分区的所有权信息。


#### 消费者线程模型

- 方案1：一个线程对应一个消费实例，所有的消费实例属于同一个消费组，每一个消费线程消费一个或者多个分区消息。

    缺点：并发程度受限于分区数量；每一个线程都需要维护TCP连接

- 方案2：一个线程拉取信息，然后多个线程处理业务数据。

    缺点：对消息的顺序处理比较困难

### kafka分区的目的

分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。

- 水平扩展：分区允许 Kafka 主题的数据被水平分割和分布到多个节点（broker）上。每个分区都可以独立地存储和处理消息，从而支持系统的横向扩展。通过增加分区数量，可以增加 Kafka 集群的处理能力

- 负载均衡： Kafka 可以将主题的分区分配给不同的 broker，实现负载均衡

- 并行处理：分区使得多个消费者能够并行地处理主题下的消息

- 容错性：每个分区的数据都会被多个副本分布在不同的节点上，确保在某个节点发生故障时，仍然能够继续提供服务。


### kafka的分区策略

- RangeAssignor 

    - 策略的核心思想是将分区范围分配给消费者

    - 假设 n = 分区数／消费者数量，m= 分区数％消费者数量，那么前m个消费者每个分配n+l个分区，后面的(消费者数量-m)个消费者每个分配n个分区

- RoundRobinAssignor

    - 将消费组内所有的消费者以及消费者订阅的所有主题分区排序，然后通过轮询的方式将分区依次分配给每一个消费者。

- stick


### 日志存储

#### kafka主题的逻辑结构

一个主题（逻辑概念）可以包含多个分区（每个分区不同的节点），一个分区对应一个Log文件（文件夹），一个Log文件可以切分为多个日志分段（log segment），一个logSegment对应一个日志文件和两个索引文件。

#### logSegment的结构

基准偏移量：每个LogSegment都有一个基准偏移量baseOffset, 用来表示当前LogSegment中第一条消息的offset。日志文件和索引文件根据偏移量命名

- 日志文件：.log文件

- 偏移量索引文件：.index文件

- 时间戳索引文件：.timeindex文件

#### 日志索引

- 偏移量索引：每一条记录中存储相对索引和日志的物理位置，使用二分查找根据偏移量快速定位物理位置

- 时间戳索引：每一条记录中存储时间戳和相对偏移量，使用二分查找快速找到相对偏移量，然后再到偏移量索引文件中查找日志的物理位置。


### 事务

#### 消息传输保障层级

- at most once

- at least once

- exactly once

对于kafka的生产者而言，生产者可以重试确保消息写入成功，因此是at least once。对于消费者而言存在重复消费和消息丢失两种情况。

#### 如何实现 exactly once?

- 幂等：对接口的多次调用所产生的结果和调用一次是一致的。kafka通过在broker上为每一个分区维护一个<pid, 分区>的序列号，确保生产消息的唯一性。

    - sn_new = sn_old + 1，broker会接收

    - sn_new < sn_old + 1，重复写入，丢失

    - sn_new > sn_old + 1，抛出异常

    - kafka的幂等：单个生产者会话中单分区幂等

- 事务：事务可以保证对多个分区写入操作的原子性




## etcd

## zookeeper
