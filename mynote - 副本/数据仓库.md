<!--
 * @Author: kekexili1230 457738564@qq.com
 * @Date: 2024-01-31 14:08:57
 * @LastEditors: kekexili1230 457738564@qq.com
 * @LastEditTime: 2024-01-31 14:44:24
 * @FilePath: /mynote/数据仓库.md
 * @Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
-->
# 数据仓库相关知识

## 数据流程

- 数据采集、转化、加工

- 数据存储（hdfs）

- 数据处理：

    - 离线数据处理：spark

    - 实时数据处理：kafka，flink

- 数据落地：

    - hive

    - hbase

- 数据分析：

    - 报表

    - 大屏显示

    - 推荐系统

    - 用户画像

    - 数据分析

## ELK

ELK是一种用于日志管理和分析的开源软件堆栈，包括

- ES：用于存储和检索大量数据

- Logstash：是一个用于日志收集、处理和传输的数据管道工具。它可以从多个来源收集日志数据，对数据进行过滤、转换和丰富，然后将其发送到Elasticsearch进行存储和检索。

- kibana：是一个用于数据可视化的工具，提供了一个用户友好的界面，让用户能够以图形化的方式探索、分析和可视化Elasticsearch中的数据

### filebeat vs logstash

- 主要用于轻量级的日志收集和转发，适用于简单的日志转发场景，如从文件中收集日志，资源消耗较低。

- 适用于复杂的日志数据处理，包括解析、转换和丰富多源数据，相对较重，消耗较多的资源，适用于需要进行复杂数据处理的场景，但需要更多资源。

### filebeat的工作原理

filebeat结构：

- inputs: 一个input负责管理harvesters和寻找所有来源读取

- harvesters（收集器）：为每个文件启动一个harvester，harvester负责读取单个文件的内容。harvester逐行读取每个文件，并将内容发送到输出（output）。

- output可以是logstash也可以ES 



