# 工作总结

## 第一、ITOA

### ITOA简介

机器分析决策系统旨在为用户提供一个海量机器数据分析处理平台，在网络、应用、用户、视频、无线、安全、日志、监控等多个层面为用户提供全方位的监控、分析、处理和预测。主要包括以下几个组件：WA（无线）、LDP（日志）、NDP（网流）、DE（DataEngine）、ITOA等。

- WA：WA通过对接用户的AP管理系统，获取AP实时在线设备信息、上网认证系统的认证数据。这些数据可以从H3C iMC设备获取。在线数据可以获取终端和AP信息的连接关系，将AP位置近似为终端位置。通过上网认证信息可以关联人员信息。两者结合可以生成轨迹信息。

- NDP：提供网络流量、应用分析、用户分析等功能模块

- LDP：分析设备日志数据

从功能模块划分，ITOA包括以下几大模块：

- 业务监控：业务列表、业务告警、重大活动保障

- 网络态势：

    - 网络态势监测：容量规划、拥塞分析、流量回溯、网络异常监测（恶意域名）、安全事件、僵尸网络（流量监测、域名监测、僵尸主机）、网络质量

    - 应用态势：应用概览、应用特征图谱、热点应用分析、应用信息管理、僵尸应用管理

    - 用户态势：
    
      - 网络行为：用户概览、用户流量查询、用户行为审计、学生上网分析（应用时长、上网时长、个体时长）、异常用户分析（失联用户）

      - 时空行为：区域热度（以AP为单位，以区域为单位分析）、轨迹分析（以用户为单位进行分析）

      - 用户信息管理：内网用户管理、学生用户管理

- 数据管理：

    - 数据采集

      - 数据源
       
        - 通用数据源（hdfs、kafka）

        - 设备数据源（机器设备）

        - 数据库数据

     - 文件采集

     - TCP、UDP采集

    - 数据分析

    - 数据清理

    - 数据展示

    - 数据转发

- 系统

    - 资源管理：资产管理、AP信息

    - 系统管理：权限管理
    
    - 日志管理：操作日志、系统日志
    
    - 系统告警：告警历史、告警查询


### 算法模型

- 算法模型：

  - 容量规划、基线计算、应用健康度、磁盘故障预测、高危操作、敏感访问、恶意域名



#### KPI基线

1. 指数平滑算法

 - 一次指数平滑算法：$F_{t+1} = \alpha * Value_{t} + (1 - \alpha) * F_{t}$，用下列公式表示更容易理解

$F_{t+1} = F_{t} + \alpha * \sigma_{t}$，其中 $\sigma_{t}$ 表示预测值与真实值之间的误差$\sigma_{t} = Value_{t} - F_{t}$
 
 - 如何确定平滑系数？

  - 经验法，根据经验确定平滑系数

  - 交叉验证

    - 候选一组平滑系数

    - 将数据集分为训练集和验证集，并按照时间序列划分，训练集位于验证集之前。

    - 使用候选组中的每一个平滑系数，结合训练集中的数据，应用指数平滑法来拟合数据。然后计算验证集和拟合数据的均方误差，最后选择产生最小均方误差的平滑系数

  - 二次指数平滑法

  二次指数平滑法增加了趋势的考虑，即预测值包含两部分：水平预测+趋势预测。水平预测，对水平值采用一次指数平滑算法预测 
    
      $L_{t} = \alpha * y_{t} + (1 - \alpha) * (L_{t} + T_{t-1}) $, 其中$(L_{t-1} + T_{t-1}) = F_t$

  趋势值，对趋势值采用一次指数平滑算法预测 
    
      $ T_{t} = \beta * (L_t - L_{t}) + (1 - \beta) * T_{t - 1} $ 

  预测值 
    
      $F_{t+h} = L_t + h * T_t$ 

2. 利用均值方差

利用正太分布，$E+\sigma, E+2*\sigma, E+3*\sigma$构建动态基线

3. 利用ARMA模型

4. 多项式回归

5. 最小二乘法

6. 随机森林


#### 应用健康度

- 主要利用丢包率和时延两个指标计算应用的健康程度

- 每一个应用都使用这两个指标计算应用健康度，指标之间的权重由相关标准和业务人员给出

- 应用分为不同的类型，每种类型的应用指标权重不同，每种应用对指标阈值的要求也不同，举例说明如下：

游戏类应用对时延要求较高，因此和丢包率相比，权重较大。时延可以分为三个范围（t1, t2, t3），如果 T > t1，好； t1 < T < t2, 中；t2 < T < t3 差; T > t3 不可用

- 利用变异系数法求得指标的波动情况，变异系数计算方法：$CV = \frac{E}{\sigma}$

- 因此应用健康度的计算公式是：$H = W_{delay} * Score_{delay} * \frac{1}{CV_{delay}}  + W_{loss} * Score_{loss} * \frac{1}{CV_{loss}} $


### 任务管理

任务管理模块是ITOA系统的基础服务之一，负责配置、调度、运行、监控整个系统的采集和分析任务。任务管理模块包括三个子模块：Manager，Scheduler，Worker。其中Manager负责管理执行节点以及配置、调度、运行、监控任务，Scheduler负责处理调度策略，Worker负责执行具体任务。


任务管理模块涉及到的技术栈包括：Spring Boot、PostgreSQL、MyBatis、多线程以及K8s。

涉及到的技术点：
（1）从配置中心拿数据，使用springboot的技术栈

#### 任务状态

1. 对于内置任务：未启动、启动、暂停、停用。

未启动 -> 启动 -> 暂停 -> 停用。其中暂停和停用的区别：暂停表示配置不丢失、停用表示彻底删除配置信息

2. 对于用户自定义任务：新增、删除

通过接口展示配置信息 -> 用户使用配置信息 -> 可以通过配置文件和环境变量的形式将参数传给任务。

通过shell脚本执行任务，将环境变量传给任务。也可以由任务读取配置文件然后执行

3. 在实现中，可以用有限状态机描述任务状态的变化

- 任务下发使用异步方式：

  - 任务创建下发后，插入数据库一条任务记录，然后异步执行任务的下发

    - 利用工厂模式，根据任务类型使用具体的任务工厂类

      - Task : create, start, stop, delete, monitor, config, update

        - DockerTask

          - SchedulerDockerTask

            - Job

          - StreamDockerTask

            - DaemonSet

            - deployment

        - AgentTask

          - SchedulerAgentTask

          - StreamAgentTask


4. 任务管理中任务设计思路：

- 程序：任务执行的是什么？

  - 程序类型、程序名称、程序文件、程序配置文件、系统参数、程序参数、程序的执行命令

- 执行：控制任务的执行：

  create, start, stop, delete, monitor, config, update, edit 包括如下类型

  - scheduler Task

    - AgentScheduler

      - 在代理节点上执行的定时调度任务

    - DockerScheduler

      - 在itoa-agent容器中自行的定时调度任务

  - stream Task

    - AgentStream：在代理节点执行的流出来任务，例如数据采集任务

    - DockerStream：在容器中执行的定时调度任务

      - Deployment

      - DaemonSet


#### 任务类型

- 根据任务是否终止

    - Stream

    - Job

      - 只调度一次

      - 定时调度

        - 起始时间、终止时间、步长、时间单位

        - cron表达

- 根据语言类型：

    - java: java <systemArgs> -cp <javajar>.jar <mainclass> <configfile> <args>

    - flink

    - spark

    - python: python <systemargs> python.zip <configfile> <args>
 
    - shell: 

    - logstash

    - filebeat

#### 代理的类型

- 集群代理：

  - 物理机

  - 容器

- 用户节点代理：用户提供权限，任务管理下发

- 用户节点代理：提供安装包，用户安装


#### 数据库设计

- task_conf: 内置任务信息

- task_info：运行任务信息，任务Id，配置信息

- task_history：保存调度历史信息，用于查看日志详情、清理历史日志


#### 关键问题

1. 如何防止任务堆叠？

- 任务执行完毕会向任务管理通知任务状态

- 触发任务时，检查上一个任务是否在调度中，如果正在调度，则忽略；否则，继续调度

2. 如何防止任务卡死

- 记录任务本次调度和下一次调度的事件

- 启动定时调度任务，检查运行中的任务，当前时间是否超过下一次调度时间的阈值（阈值由步长*因子决定）。如果超过，则强制停止任务。

3. 如何检查代理连接状态

- 启动定时调度任务，遍历代理相关接口

4. 如何监控任务

- 启动定时调度任务，定期检查任务异常状态

5. 如果创建k8s容器

- 使用fabric8第三方库


## 代理

1. 通过shell脚本安装，增加开机启动

2. 对于stream类型的任务，将任务信息写入文件，启动定时任务监控任务是否存在，如果不存在，则根据配置文件获取任务信息，启动任务

3. 对于任务使用nohup <sh command> &的形式执行，并将执行结果返回给任务管理模块




## quartz复习

1. Quartz中的几个核心概念

- Job表示一个工作，要执行的内容

- JobDetail表示一个具体要执行的调度程序

- Trigger表示一个调度参数的配置

- Scheduler代表一个调度容器，容器中可以注册多个JobDetail和Trigger

- listener用于根据调度程序中发生的事件执行操作

2. 使用方法

- 由Factory生成 -> Scheduler

- triggerBuilder生成trigger

- JobBuilder生成JobDetail

- 向容器中注册scheduler.schedulerJob(jobDetail, trigger)

- 启动容器scheduler.start()

3. 使用triggerListener


## 第二、DC数据中心

### 相关概念

1. Telemetry vs SNMP

SNMP（Simple Network Management Protocol）和Telemetry都是用于监控和管理网络设备的工具，但它们在设计和实现上有一些区别SNMP（Simple Network Management Protocol）和Telemetry都是用于监控和管理网络设备的工具，但它们在设计和实现上有一些区别

- 数据传输方式：

  - SNMP： 使用轮询（polling）机制。管理系统定期查询代理设备以获取数据。

  - Telemetry： 使用推送（push）机制。设备根据需要发送实时数据，而不等待查询请求。

- 实时性：

  - SNMP： 数据的实时性相对较低，因为数据的更新频率取决于轮询的时间间隔。
  - Telemetry： 提供更高的实时性，因为数据是根据事件的发生实时推送的。

- 效率和带宽利用：

  - SNMP： 轮询可能导致带宽浪费，因为即使没有变化，也会定期查询数据。

  - Telemetry： 通过事件触发的方式，可以避免不必要的数据传输，提高带宽利用效率。

- 数据格式：

  - SNMP： 使用标准的MIB（Management Information Base）结构定义数据。

  - Telemetry： 可以使用各种数据格式，如JSON、Protocol Buffers等。

- 安全性：

  - SNMP： SNMPv3引入了较好的安全性，包括加密和身份验证。

  - Telemetry： 通常也支持安全特性，可以使用加密和身份验证来保护传输的数据。

- 扩展性：

  - SNMP： 使用MIB进行管理，可以通过定义新的MIB来扩展管理功能。

  - Telemetry： 通常支持灵活的数据模型，可以根据需要定义新的数据结构。

- 适用场景：

  - SNMP： 适用于相对简单的网络监控，对实时性要求不高的情况。

  - Telemetry： 更适用于复杂的、要求实时监控的网络环境，特别是在大规模、高密度的部署中。

- 协议版本：

  - SNMP： 主要有 SNMPv1、SNMPv2c、SNMPv3 等版本。

  - Telemetry： 没有一个特定的版本，因为它通常是通过不同的传输协议（如gRPC、HTTP/2）实现的。

2. Telemetry的实现方式包括：

- gRPC

- INT

- Telemetry Stream

- ERSPAN

3. Telemetry的优势：

- 数据采集精度高，类型丰富，例如CPU和内存状态、接口的物理信息（光模块状态和带宽利用率），接口统计信息（丢包、错包），表项资源（转发表，ACL流表，虚接口

- 一次订阅重复上报


### 主机管理

主机管理模块包括主机管理和分析两部分功能。主机管理设计主机的查询、导入以及同步主机。主机分析功能基于ARP和ND表象，对识别范围内的主机进行自动发现。并根据ERSPAN或者Telemetry Stream镜像采集的TCP流，对由流量的主机进行上、下线情况进行追踪，确定主机的上下线状态和时间，并记录主机的接入Fabric，接入设备，接入接口，网关接口，网关IP，VRF等信息

1. 什么是主机

  数据中心里物理机、虚拟机或者服务器

2. 虚拟机迁移的场景

  - 宿主机（物理机故障），虚拟机进行迁移

  - 物理服务器过载，资源不足，影响虚拟机的性能，需要迁移虚拟机

  - RAID卡故障造成虚拟IO性能下降，需要迁移虚拟机

3. 虚拟机如何迁移？

虚拟机在二层网络中才能完成迁移，虚拟机在迁移过程中应该确保IP、MAC地址不变。

- IP地址不变保证TCP连接不中断

- MAC地址一般不发生变化，只需更新MAC地址转发表即可

4. 主机唯一标识，当前实现是（IP，MAC，Access），理论上（IP，MAC，VPN）更合适

5. 主机管理中的主机来源有：

  - 手动导入主机

  - 控制器同步主机

  - 自动发现主机

      - 从arp和nd表发现主机，host表

6. 主机上下线

  - 上线：流量中发现主机
  
      - arp存在老化时间，主机可能已下线，但是表尚未老化。因此arp表中存在主机信息，主机未必在线

      - 采集arp表使用定时同步法，存在一定的延迟。使用监控主机流量，可以快速发现上线主机

  - 下线：arp表或者nd表中没有主机信息

      - 没有主机信息，未必代表主机下线。如果主机一段时间内没有流量，且arp表老化，可能会出现误下线

      - 无法从流量的角度判断主机是否已下线

### 数据面验证

1. 数据面验证通过采集网络设备表项数据，构建转发模型。在业务变更后，验证网络实际转发行为是否和用户预期一致。用户可以通过验证结果确认变更是否符合预期，是否引入问题。

- 可达性验证：输入设备间的IP地址。根据源IP地址遍历路由信息找到起始设备，在起始设备上根据路由信息模拟转发，当设备到达目的设备时，验证通过

- 隔离性验证：输入设备间的IP地址。

- 子网互访性验证：验证不同子网可达性。DPV根据源子网IP地址遍历路由信息找到起始设备，在起始设备上根据路由信息模拟转发，当设备到达目的子网时，验证通过

- 整网预置可达性BGP对等体验证、整网预置可达性vxlan隧道验证，整网预置一致性验证，整网预置存在性路由环路验证，整网预置存在性路由黑洞验证。



## 第三、NFA
### 告警中心

### 数据管理

### 采集器-协议分析

1. TLS协议，交过过程

2. HTTP协议，交互过程

3. libpcap包的使用

libpcap包捕获机制是在数据链路层增加一个旁路处理，并不干扰系统自身的网络协议栈的处理，对发送和接收的数据包通过linux内核做缓冲处理，最后直接传递给应用层使用。

- 如何将数据链路层的报文发送给用户？

  使用PF_PACKET协议族原始套接字和SOCK_RAW类型，将数据链路层报文发送给用户态空间

- libpcap的主要功能

  - 数据包捕获：捕获经网卡的原始数据包（流量嗅探器）

  - 自定义数据包发送：构造任何格式的原始数据包（网络流量发生器）

  - 流量采集与统计：采集网络中的流量

  - 规则过滤：提供自带规则过滤功能（报文过滤）

- 在容器探针中，pod采用DaemonSet的方式分布在各节点。Pod需要能够看到宿主机的网络信息，需要配置hostNetwork: true。

- 探针使用GRE封装转发报文

  - socket(AF_INET, SOCK_RAW, IPPROTO_GRE);

    - AF_INET：表示要使用的地址族，这里是 IPv4 地址族。AF_INET 指定了使用 IPv4 地址结构。

    - SOCK_RAW：表示套接字类型，这里是原始套接字。原始套接字允许应用程序直接处理网络层（IP）的数据包，而不是依赖于操作系统处理传输层（TCP、UDP）的数据。

    - IPPROTO_GRE：指定协议，这里是 GRE（Generic Routing Encapsulation）协议。原始套接字允许应用程序直接访问指定协议的数据包。

  - 按照GRE报文格式，构建GRE报文

  - 使用socket发送报文



### 采集器报文回溯分析

1. B+树

2. NDPI

3. DPDK

4. RAID 5
